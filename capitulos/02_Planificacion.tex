\chapter{Planificación}

En este capítulo se aborda el plan de trabajo a seguir para la realización de este estudio. En primer lugar se estimarán los requisitos a satisfacer por el mismo, a fin de lograr los objetivos planteados, y a continuación se planteará su planificación, como los presupuestos necesarios, la carga de trabajo por fase de dicho estudio o los tiempos esperados de realización para cada una de ellas.

\section{Requisitos de investigación}

Al tratarse de un trabajo de investigación, un análisis de requisitos habitual no puede ser aplicado correctamente a esta situación. En su lugar, sin embargo, se proponen una serie de objetivos a cumplir para la conclusión del estudio. En el caso de este en particular, los distintos requisitos que se pueden distinguir son:

\begin{enumerate}
	\item{\textbf{Realizar una investigación primeriza acerca de los algoritmos socioinspirados}: revisar la literatura buscando información sobre lo que representan estos algoritmos, valorar las motivaciones que impulsen a realizar el estudio y obtener propuestas de dichos algoritmos.}
	\item{\textbf{Seleccionar las propuestas más interesantes}: de entre todos los algoritmos socioinspirados que se hayan podido encontrar en la fase anterior, seleccionar aquellos que resulten más interesantes o que aporten un enfoque diferente al panorama actual. También se busca que pertenezcan a campos distintos dentro de esta rama de algoritmos, a fin de aportar un punto de vista sobre las principales vertientes que existen.}
	\item{\textbf{Analizar a fondo las propuestas seleccionadas}: el principal objetivo aquí es ser capaz de entender qué metodología sigue cada algoritmo, en qué carga teórica basa sus técnicas y qué es capaz de conseguir con lo que propone. Se intentará asemejar cada propuesta con otros algoritmos evolutivos que sean más reconocibles por cualquier investigador iniciado en el campo.}
	\item{\textbf{Implementar aquellos algoritmos de los que no se posea código fuente}: ya que el análisis de este trabajo es experimental, es necesario contar con el código de los algoritmos para poder realizar adecuadamente las distintas pruebas. Una implementación propia facilita a su vez que se pueda adaptar el código de dicho algoritmo para seguir unas pautas de formato de soluciones comunes a todo el estudio.}
	\item{\textbf{Estimar los parámetros de los algoritmos}: si se desconocen los parámetros ideales con los que ejecutar un algoritmo, se someterá a una pequeña experimentación con varias combinaciones de parámetros a fin de seleccionar los que mejores resultados aporten.}
	\item{\textbf{Realizar la experimentación}: utilizar los algoritmos implementados y un benchmark de referencia para obtener resultados. Los algoritmos se lanzarán con las combinaciones de parámetros extraídas del apartado anterior, en función de las conclusiones obtenidas.}
	\item{\textbf{Construcción de tablas y gráficas experimentales}: en base a los resultados obtenidos, se pueden disponer los datos en tablas representativas, así como en gráficas de convergencia con las que comprobar el comportamiento de cada algoritmo a lo largo de las ejecuciones.}
	\item{\textbf{Estudio analítico de los datos obtenidos}: comparar los resultados de cada algoritmo con los de un algoritmo evolutivo de referencia, así como entre ellos, a fin de descubrir cómo se comportan con una serie variada de funciones complejas y qué algoritmos destacan más sobre los otros.}
	\item{\textbf{Extraer conclusiones del estudio realizado}: dar una visión analítica de la eficacia de los algoritmos socioinspirados, basándose en la comparativa con el algoritmo de referencia, y justificar qué propuestas son más prometedoras.}
	\item{\textbf{Trabajos futuros a realizar}: valorar en qué aspectos se puede innovar en este campo, aportar propuestas de mejora para las técnicas socioinspiradas y realizar un ajuste minucioso de parámetros para los algoritmos con mayor potencial.}
\end{enumerate}

Con los requisitos planteados, la planificación del trabajo debe abarcar cada uno de esos pasos y estimar un tiempo a priori con el que se pueda solventar cada requisito. Además, debe abarcar todo el material e infraestructura necesarios y, junto al tiempo estimado, dar una idea del presupuesto que requiere realizar este estudio.

\section{Planificación del trabajo}

Este apartado está subdividido en la estimación de costes y la estimación de tiempo. Es necesario en un primer momento valorar el coste de la infraestructura y de todo aquel material que no esté disponible de forma libre o gratuita, y saber de qué presupuesto inicial debe partir el estudio. Además, la estimación de tiempo debe ser competente y ser capaz de abarcar los mejores y peores casos prácticos, para que no sea necesario aplazar la entrega a última hora debido a una mala planificación, y deberá influir a su vez en el coste, pues es un recurso más con el que se cuenta.

\subsection{Estimación de coste de materiales e infraestructura}

En primer lugar se tendrá en cuenta la máquina con la que se ha desarrollado el grueso de este estudio. Se trata de un ordenador portátil de la marca Acer, del año 2012, y que cuenta con un procesador i5-2450M a 2.5GHz, así como con 8GB de memoria RAM DDR3, un HDD de 1TB y un SSD de 120GB, que ha sido añadido posterior a la compra del equipo. Con este equipo se han realizado aquellas tareas de documentación, revisión de la literatura y redacción de la memoria, así como las labores de desarrollo e implementación de los algoritmos.

Para obtener la información y documentación requerida para el trabajo ha sido necesaria una red de internet de banda ancha, disponible tanto en el lugar de desarrollo del trabajo como en las instalaciones de la Universidad de Granada cuando ha sido necesario. Gracias a los convenios que la Universidad establece con algunas bases de datos documentales como Scopus \cite{scopus-website} ha sido posible acceder a multitud de \textit{papers} y publicaciones sobre el tema a investigar. Además ha sido de mucha utilidad la página ResearchGate \cite{research-gate-website} para acceder a otros papers no encontrados en Scopus.

El desarrollo del trabajo ha sido realizado completamente sobre el sistema operativo Linux, con una distribución Ubuntu 17.10, por lo que es totalmente libre y carente de costes. Las principales herramientas de software utilizadas también han sido de código abierto por lo que no han conllevado coste adicional, utilizando como IDE principal Visual Studio Code \cite{vscode-github} y escribiendo la memoria en LaTeX utilizando el software TeXstudio \cite{texstudio}.

Para la ejecución de los experimentos, debido al procesador antiguo del ordenador principal, así como de los grandes cómputos que son necesarios para la experimentación, el departamento de Ciencias de la Computación e Inteligencia Artificial de la Universidad de Granada (DECSAI) facilitó el acceso a su clúster Hércules \cite{cluster-hercules}, ubicado en el Centro de Investigación en Tecnologías de la Información y de las Comunicaciones de la Universidad de Granada (CITIC-UGR). Este clúster, de acuerdo a la fuente anteriormente citada, <<posee 46 nodos, cada uno de ellos equipado con un procesador Intel Core i7 930 a 2.8 GHz, 24 GB de RAM y HDD SATA2 de 1TB. Los nodos están interconectados mediante dos redes internas de tipo Gigabit Ethernet. El sistema incluye una cabina RAID con capacidad para 72 TB. Se emplean los S.O. Fedora 16 y CentOS 6.2>>. Se trata por tanto de una máquina mucho más potente que la utilizada en el estudio, y servirá para obtener de forma más eficaz los resultados de los experimentos.

De todo este material expuesto en los párrafos anteriores, el trabajo sólo ha requerido comprar el ordenador portátil personal y la red de banda ancha disponible en el lugar de desarrollo del mismo, dado que se trata de recursos personales. El resto de la infraestructura y materiales o bien han sido productos de software libre o han sido aportados por la Universidad de Granada.

\subsection{Distribución de tiempo entre tareas}

Organizar la carga de trabajo en las distintas fases del proceso es una labor que debe realizarse antes del comienzo del mismo. Gracias a ello se pueden plantear fechas de entrega, acotar los tiempos dedicados a cada tarea y, por consiguiente, ayudar al rendimiento general del problema.

En primer lugar, la labor de revisión de la literatura y documentación abarcará todo el proceso, ya que es habitual que a lo largo del desarrollo sea necesario acudir a nuevos documentos que contengan la información deseada. Sin embargo, de la primera tarea se dedicará una semana a seleccionar las propuestas más interesantes a priori, una vez conocidos los principales algoritmos. En dicha labor, cabe destacar la ayuda de este <<bestiario>> de algoritmos evolutivos recopilado por el usuario \textit{fcampelo} en la plataforma GitHub \cite{ec-bestiary-github}, que ha servido para descubrir algunos de los algoritmos escogidos para el estudio.

En cuanto a la comprensión de cada algoritmo y la implementación del mismo, resulta una tarea compleja y que tiene una alta carga de trabajo. A pesar de que estos algoritmos no están necesariamente plagados de complejas fórmulas matemáticas, sí que es necesario escudriñar a fondo toda la información recabada de su definición en la literatura, a fin de poder realizar una implementación adecuada del mismo. Una estimación factible es que comprender e implementar cada algoritmo puede llevar entre dos semanas y un mes, dependiendo de la complejidad del mismo.

Antes de plantear los experimentos definitivos se ha propuesto realizar una estimación de parámetros, debida a la poca información que algunos de los \textit{papers} esclarecen acerca de los mismos. Esto llevará un par de semanas para elegir el benchmark, preparar el entorno de trabajo y ejecutar los algoritmos. Lógicamente, cuantas más combinaciones de parámetros se quieran probar, más extenso será este tiempo.

La experimentación final requerirá de unos días más para seleccionar dichos parámetros adecuadamente, preparar una serie de scripts que lanzar en paralelo y recopilar los datos de forma conjunta. Una vez conseguido esto, la construcción de tablas y gráficas será también casi directa, aunque trabajosa, y puede llevar otra semana.

Finalmente, extraer conclusiones de los resultados puede ser más sencillo si se conocen los algoritmos y se han trabajado correctamente, de forma que sea fácil interpretarlos y descubrir patrones en los mismos. Al ser una tarea tan diversa y poco acotada, una extracción de conclusiones puede llevar desde una semana hasta más de un mes.

En resumen, la ruta de trabajo trazada por estas tareas puede estimarse en que llevará entre unos 6 y 7 meses, aunque naturalmente ese espacio de tiempo puede variar dependiendo de lo que se invierta cada día. Es de importancia recordar que el coste del tiempo invertido también debe ser igualmente valorado tal y como se hace con el coste de los materiales. Partiendo de la base de que este estudio es, en esencia, un trabajo de investigación en un campo puntero tecnológicamente, podría estimarse el coste total del trabajo como una media entre el sueldo a jornada completa de un ingeniero informático y el de un investigador de un departamento de universidad durante el transcurso del mismo.

Siendo un valor estimado de 18 euros/hora para una profesión como esta, a 6 meses trabajando (20 días al mes) a 8h diarias, se estipularía el presupuesto del proyecto en 17280 euros.